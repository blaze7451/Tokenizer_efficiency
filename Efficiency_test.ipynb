{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path1 = r\"yentinglin/Taiwan-LLM-7B-v2.0.1-chat\"\n",
    "path2 = r\"google/gemma-7b\"\n",
    "path3 = r\"INX-TEXT/Bailong-instruct-7B\"\n",
    "path4 = r\"MediaTek-Research/Breeze-7B-Instruct-v1_0\"\n",
    "path5 = r\"taide/TAIDE-LX-7B-Chat\"\n",
    "path6 = r\"taide/Llama3-TAIDE-LX-8B-Chat-Alpha1\"\n",
    "\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(path1)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(path2)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(path3)\n",
    "tokenizer_4 = AutoTokenizer.from_pretrained(path4)\n",
    "tokenizer_5 = AutoTokenizer.from_pretrained(path5)\n",
    "tokenizer_6 = AutoTokenizer.from_pretrained(path6)\n",
    "tokenizer_7 = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gold_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究...</td>\n",
       "      <td>[看似, 簡單, ，, 只, 是, 二, 選, 一, 做, 決擇, ，, 但, 其實, 他們...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>其便當都是買來的，就算加熱也是由媽媽負責（後來揭曉其實是避免帶來厄運），父親則在電視台上班。</td>\n",
       "      <td>[其, 便當, 都是, 買來, 的, ，, 就算, 加熱, 也是, 由, 媽媽, 負責, （...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>這次遊行最大的特色，在於越來越多年輕人上街遊行，而且當中不乏行動激烈的躁少年。</td>\n",
       "      <td>[這, 次, 遊行, 最大, 的, 特色, ，, 在, 於, 越來越, 多, 年輕, 人, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>懷孕期為421至457日。</td>\n",
       "      <td>[懷孕, 期, 為, 421, 至, 457, 日, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>婷婷向昏迷中的婆婆訴說，為什麼生活會與她想像的不一樣。</td>\n",
       "      <td>[婷婷, 向, 昏迷, 中, 的, 婆婆, 訴說, ，, 為, 什麼, 生活, 會, 與, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究...   \n",
       "1     其便當都是買來的，就算加熱也是由媽媽負責（後來揭曉其實是避免帶來厄運），父親則在電視台上班。   \n",
       "2            這次遊行最大的特色，在於越來越多年輕人上街遊行，而且當中不乏行動激烈的躁少年。   \n",
       "3                                      懷孕期為421至457日。   \n",
       "4                        婷婷向昏迷中的婆婆訴說，為什麼生活會與她想像的不一樣。   \n",
       "\n",
       "                                         gold_tokens  \n",
       "0  [看似, 簡單, ，, 只, 是, 二, 選, 一, 做, 決擇, ，, 但, 其實, 他們...  \n",
       "1  [其, 便當, 都是, 買來, 的, ，, 就算, 加熱, 也是, 由, 媽媽, 負責, （...  \n",
       "2  [這, 次, 遊行, 最大, 的, 特色, ，, 在, 於, 越來越, 多, 年輕, 人, ...  \n",
       "3                      [懷孕, 期, 為, 421, 至, 457, 日, 。]  \n",
       "4  [婷婷, 向, 昏迷, 中, 的, 婆婆, 訴說, ，, 為, 什麼, 生活, 會, 與, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = r\"E:\\Tokenizer\\Efficiency\\Treebanks.json\"\n",
    "df = pd.read_json(json_path, lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4997/4997 [00:03<00:00, 1480.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_length</th>\n",
       "      <th>character_length</th>\n",
       "      <th>taiwan_length</th>\n",
       "      <th>gemma_length</th>\n",
       "      <th>bailong_length</th>\n",
       "      <th>breeze_length</th>\n",
       "      <th>taide_length</th>\n",
       "      <th>llama3_length</th>\n",
       "      <th>gpt4_length</th>\n",
       "      <th>jieba_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>99</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_length  character_length  taiwan_length  gemma_length  bailong_length  \\\n",
       "0           40                58             99            42              41   \n",
       "1           29                46             93            31              30   \n",
       "2           25                39             64            27              21   \n",
       "3            8                13             22            13              10   \n",
       "4           19                27             56            19              19   \n",
       "\n",
       "   breeze_length  taide_length  llama3_length  gpt4_length  jieba_length  \n",
       "0             42            40             48           83            35  \n",
       "1             30            31             46           73            29  \n",
       "2             25            25             34           57            24  \n",
       "3             13            13             11           14             8  \n",
       "4             19            20             26           50            19  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(df)\n",
    "gold_list = []\n",
    "character_list = []\n",
    "taiwan_list = []\n",
    "gemma_list = []\n",
    "bailong_list = []\n",
    "breeze_list = []\n",
    "taide_list = []\n",
    "llama3_list = []\n",
    "gpt_list = []\n",
    "jieba_list = []\n",
    "\n",
    "for i in tqdm(range(length)):\n",
    "    text = df.iloc[i][\"text\"]\n",
    "    gold_length = len(df.iloc[i][\"gold_tokens\"])\n",
    "    character_length = len(text)\n",
    "    taiwan_length = len(tokenizer_1.tokenize(text))\n",
    "    gemma_length = len(tokenizer_2.tokenize(text))\n",
    "    bailong_length = len(tokenizer_3.tokenize(text))\n",
    "    breeze_length = len(tokenizer_4.tokenize(text))\n",
    "    taide_length = len(tokenizer_5.tokenize(text))\n",
    "    llama3_length = len(tokenizer_6.tokenize(text))\n",
    "    gpt_length = len(tokenizer_7.encode(text))\n",
    "    jieba_length = len(jieba.lcut(text))\n",
    "    gold_list.append(gold_length)\n",
    "    character_list.append(character_length)\n",
    "    taiwan_list.append(taiwan_length)\n",
    "    gemma_list.append(gemma_length)\n",
    "    bailong_list.append(bailong_length)\n",
    "    breeze_list.append(breeze_length)\n",
    "    taide_list.append(taide_length)\n",
    "    llama3_list.append(llama3_length)\n",
    "    gpt_list.append(gpt_length)\n",
    "    jieba_list.append(jieba_length)\n",
    "\n",
    "dictt = {\n",
    "    \"gold_length\": gold_list,\n",
    "    \"character_length\": character_list,\n",
    "    \"taiwan_length\": taiwan_list,\n",
    "    \"gemma_length\": gemma_list,\n",
    "    \"bailong_length\": bailong_list,\n",
    "    \"breeze_length\": breeze_list,\n",
    "    \"taide_length\": taide_list,\n",
    "    \"llama3_length\": llama3_list,\n",
    "    \"gpt4_length\": gpt_list,\n",
    "    \"jieba_length\": jieba_list\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(dictt)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency is defined as the number of tokens required to represent Traditional Chinese text with respect to the number of gold standard tokens on the same text, i.e.,\n",
    "\n",
    "$\\huge \\text{Efficiency} = \\frac{\\#\\text{token}_{\\text{standard}}}{\\#\\text{token}_{\\text{model}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>TAIWAN-LLM</th>\n",
       "      <th>Gemma</th>\n",
       "      <th>Bailong</th>\n",
       "      <th>Breeze</th>\n",
       "      <th>Taide 7B</th>\n",
       "      <th>Llama 3</th>\n",
       "      <th>GPT-4</th>\n",
       "      <th>jieba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.802</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.444</td>\n",
       "      <td>1.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character  TAIWAN-LLM  Gemma  Bailong  Breeze  Taide 7B  Llama 3  GPT-4  \\\n",
       "0       0.63       0.392  0.802    1.005   0.847     0.818    0.696  0.444   \n",
       "\n",
       "   jieba  \n",
       "0  1.081  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_gold = new_df[\"gold_length\"].sum()\n",
    "all_character = new_df[\"character_length\"].sum()\n",
    "all_taiwan = new_df[\"taiwan_length\"].sum()\n",
    "all_gemma = new_df[\"gemma_length\"].sum()\n",
    "all_bailong = new_df[\"bailong_length\"].sum()\n",
    "all_breeze = new_df[\"breeze_length\"].sum()\n",
    "all_taide = new_df[\"taide_length\"].sum()\n",
    "all_llama3 = new_df[\"llama3_length\"].sum()\n",
    "all_gpt4 = new_df[\"gpt4_length\"].sum()\n",
    "all_jieba = new_df[\"jieba_length\"].sum()\n",
    "\n",
    "character_efficiency = round(all_gold/all_character, 3)\n",
    "taiwan_efficiency = round(all_gold/all_taiwan, 3)\n",
    "gemma_efficiency = round(all_gold/all_gemma, 3)\n",
    "bailong_efficiency = round(all_gold/all_bailong, 3)\n",
    "breeze_efficiency = round(all_gold/all_breeze, 3)\n",
    "taide_efficiency = round(all_gold/all_taide, 3)\n",
    "llama3_efficiency = round(all_gold/all_llama3, 3)\n",
    "gpt_efficiency = round(all_gold/all_gpt4, 3)\n",
    "jieba_efficiency = round(all_gold/all_jieba, 3)\n",
    "\n",
    "\n",
    "dictt = {\"Character\": [character_efficiency], \"TAIWAN-LLM\": [taiwan_efficiency], \"Gemma\": [gemma_efficiency], \"Bailong\": [bailong_efficiency], \"Breeze\": [breeze_efficiency], \"Taide 7B\": [taide_efficiency], \"Llama 3\": [llama3_efficiency], \"GPT-4\": [gpt_efficiency], \"jieba\": [jieba_efficiency]}\n",
    "efficiency_df = pd.DataFrame(dictt)\n",
    "\n",
    "efficiency_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
